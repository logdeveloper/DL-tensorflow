{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:01.015177Z",
     "start_time": "2020-10-07T02:16:01.010191Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# tensorflow 2.3 version 말고 1.0 version 사용\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:01.047091Z",
     "start_time": "2020-10-07T02:16:01.017178Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "# one hot encoding으로 표현\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:02.274604Z",
     "start_time": "2020-10-07T02:16:01.049085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.3635654\n",
      "500 0.4084465\n",
      "1000 0.24111578\n",
      "1500 0.19025627\n",
      "2000 0.15671113\n",
      "-----------------\n",
      "[[4.6992414e-03 9.9529254e-01 8.2206279e-06]] [1]\n",
      "-----------------\n",
      "[[0.8694534  0.12154147 0.00900514]] [0]\n",
      "-----------------\n",
      "[[1.3045859e-08 3.4179259e-04 9.9965823e-01]] [2]\n",
      "-----------------\n",
      "[[4.6992414e-03 9.9529254e-01 8.2206361e-06]\n",
      " [8.6945331e-01 1.2154150e-01 9.0051424e-03]\n",
      " [1.3045859e-08 3.4179259e-04 9.9965823e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "# 분류해야하는 클래스가 3\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4,nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')\n",
    "\n",
    "# softmax 식\n",
    "# tf.matmul(X,W) + b => logit, score 라고 부르기도 함.\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "\n",
    "# cost/loss 함수 # Y는 one-hot으로 주어짐.\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 세션 초기화 하여 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict = {X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    print('-----------------')    \n",
    "    a = sess.run(hypothesis, feed_dict={X:[[1, 11, 7, 9]]})\n",
    "    print(a, sess.run(tf.argmax(a,1))) # 가장 큰값을 1로 준다.\n",
    "    \n",
    "    print('-----------------')    \n",
    "    b = sess.run(hypothesis, feed_dict={X:[[1, 3, 4, 3]]})\n",
    "    print(b, sess.run(tf.argmax(b,1))) # 가장 큰값을 1로 준다.\n",
    "    \n",
    "    print('-----------------')    \n",
    "    c = sess.run(hypothesis, feed_dict={X:[[1, 1, 0, 1]]})\n",
    "    print(c, sess.run(tf.argmax(c,1))) # 가장 큰값을 1로 준다.\n",
    "    \n",
    "    print('-----------------')    \n",
    "    abc_all = sess.run(hypothesis, feed_dict={X:[[1, 11, 7, 9],[1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "    print(abc_all, sess.run(tf.argmax(abc_all,1))) # 가장 큰값을 1로 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과는 a=1, b=0, c=2로 예측할 수 있다. \n",
    "Fancy Softmax Classifier (cross_entropy, one_hot, reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:02.289569Z",
     "start_time": "2020-10-07T02:16:02.278598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16) (101, 1)\n"
     ]
    }
   ],
   "source": [
    "# x 데이터를 통해 어떤 동물인지 예측하는 예제 \n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 동물 데이터를 불러옴.\n",
    "xy = np.loadtxt('../../../DeepLearningZeroToAll/DeepLearningZeroToAll-master/data-04-zoo.csv', delimiter =',', dtype=np.float32)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:02.320486Z",
     "start_time": "2020-10-07T02:16:02.292563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot: Tensor(\"one_hot_1:0\", shape=(?, 1, 7), dtype=float32)\n",
      "reshape one_hot: Tensor(\"Reshape_1:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 7 # 0~6까지 숫자\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "\n",
    "# 0~6까지 하나의 컬럼으로 구성된 값을 one-hot-encoding 실행\n",
    "# one hot에 사용되는 Y 값은 무조건 0부터 시작 \n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)\n",
    "print(\"one_hot:\", Y_one_hot)\n",
    "\n",
    "# one hot 작업만 하면 차원이 하나 더생기기 때문에(N차원 -> N+1차원), reshape 작업이 한번더 필요하다. \n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes]) # -1 : 앞에는 알아서..\n",
    "print(\"reshape one_hot:\", Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T02:16:03.508788Z",
     "start_time": "2020-10-07T02:16:02.322481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0\tCost: 6.723\tAcc: 0.00\n",
      "step   100\tCost: 0.636\tAcc: 0.81\n",
      "step   200\tCost: 0.418\tAcc: 0.90\n",
      "step   300\tCost: 0.312\tAcc: 0.91\n",
      "step   400\tCost: 0.247\tAcc: 0.95\n",
      "step   500\tCost: 0.202\tAcc: 0.96\n",
      "step   600\tCost: 0.170\tAcc: 0.97\n",
      "step   700\tCost: 0.146\tAcc: 0.97\n",
      "step   800\tCost: 0.128\tAcc: 0.99\n",
      "step   900\tCost: 0.114\tAcc: 0.99\n",
      "step  1000\tCost: 0.102\tAcc: 0.99\n",
      "step  1100\tCost: 0.093\tAcc: 1.00\n",
      "step  1200\tCost: 0.085\tAcc: 1.00\n",
      "step  1300\tCost: 0.079\tAcc: 1.00\n",
      "step  1400\tCost: 0.073\tAcc: 1.00\n",
      "step  1500\tCost: 0.068\tAcc: 1.00\n",
      "step  1600\tCost: 0.064\tAcc: 1.00\n",
      "step  1700\tCost: 0.060\tAcc: 1.00\n",
      "step  1800\tCost: 0.057\tAcc: 1.00\n",
      "step  1900\tCost: 0.054\tAcc: 1.00\n",
      "step  2000\tCost: 0.051\tAcc: 1.00\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "# 모델 적용\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name ='bias')\n",
    "\n",
    "# score라고도 표현\n",
    "logits = tf.matmul(X,W) +b\n",
    "\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# 이미 있는 함수를 사용하여 cost/loss func을 구해보자.\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                                labels=tf.stop_gradient([Y_one_hot])))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        _, cost_val, acc_val = sess.run([optimizer, cost, accuracy], feed_dict={X: x_data, Y:y_data})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"step {:5}\\tCost: {:.3f}\\tAcc: {:.2f}\".format(step, cost_val, acc_val))\n",
    "            \n",
    "    pred = sess.run(prediction, feed_dict= {X:x_data})\n",
    "    \n",
    "    for p,y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측값과 실제 Y 값은 거의 동일하게 보임."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "PyCharm (Doople)",
   "language": "python",
   "name": "pycharm-97521919"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
